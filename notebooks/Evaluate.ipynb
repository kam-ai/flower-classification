{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluate the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "from pandas import read_csv\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "import argparse\n",
    "from joblib import dump, load\n",
    "import os\n",
    "iris = read_csv('../data/test-data.csv')\n",
    "\n",
    "X = iris.values[:, :-1]\n",
    "Y = iris.values[:, -1]\n",
    "\n",
    "def predict(predictor, X, Y):\n",
    "    pred = predictor.predict(X)\n",
    "    return accuracy_score(Y, pred)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Get score for every model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model\n",
      "Score for model model-20191118-1947.joblib, is 0.973333\n",
      "model\n",
      "Score for model model-20191118-2052.joblib, is 0.960000\n",
      "model\n",
      "Score for model model-20191118-2053.joblib, is 0.946667\n",
      "model\n",
      "Score for model model-20191118-2054.joblib, is 0.946667\n",
      "model\n",
      "Score for model model-20191118-2055.joblib, is 0.960000\n",
      "model\n",
      "Score for model model-20191118-2056.joblib, is 0.960000\n",
      "model\n",
      "Score for model model-20191119-742.joblib, is 0.960000\n",
      "model\n",
      "Score for model model-20191119-744.joblib, is 0.946667\n",
      "model\n",
      "Score for model model-20191119-746.joblib, is 0.946667\n",
      "model\n",
      "Score for model model-20191119-756.joblib, is 0.960000\n",
      "model\n",
      "Score for model model-20191119-838.joblib, is 0.960000\n",
      "model\n",
      "Score for model model-2019413-1135.joblib, is 0.973333\n",
      "model\n",
      "Score for model model.joblib, is 0.920000\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\users\\axel\\kamai\\pythonenvs\\kamai\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.20.3 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n",
      "c:\\users\\axel\\kamai\\pythonenvs\\kamai\\lib\\site-packages\\sklearn\\base.py:306: UserWarning: Trying to unpickle estimator KNeighborsClassifier from version 0.20.3 when using version 0.21.3. This might lead to breaking code or invalid results. Use at your own risk.\n",
      "  UserWarning)\n"
     ]
    }
   ],
   "source": [
    "models = os.listdir('../models')\n",
    "scores = []\n",
    "for model in models:\n",
    "    if('.gitkeep' in model):\n",
    "        continue\n",
    "    print('model')\n",
    "    predictor = load('../models/%s' % model)\n",
    "    score = predict(predictor, X, Y)\n",
    "    scores.append(score)\n",
    "    print('Score for model %s, is %f' % (model, score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Find best model or models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best models are\n",
      ".gitkeep with score 0.973333\n",
      "model-20191119-838.joblib with score 0.973333\n"
     ]
    }
   ],
   "source": [
    "best_score_indices = np.argwhere(scores == np.amax(scores))\n",
    "best_scores = np.array(scores)[best_score_indices]\n",
    "best_models = np.array(models)[best_score_indices]\n",
    "\n",
    "if(len(best_models) == 0):\n",
    "    print('Best model is %s' % best_models[0])\n",
    "    print('with score %s' % best_scores[0])\n",
    "else:\n",
    "    print('Best models are')\n",
    "    for model, score in zip(best_models, best_scores):\n",
    "        print('%s with score %f' % (model[0], score[0]))\n",
    "        "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
